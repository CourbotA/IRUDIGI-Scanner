{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports that will be used to construct the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model,Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import * \n",
    "from tensorflow_addons.layers import InstanceNormalization\n",
    "from glob import glob\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\WORKCODE\\IRUDIGI\\IRUDIGI-Scanner\\database2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "IMG_WIDTH = 512\n",
    "IMG_HEIGHT = 512\n",
    "\n",
    "path = os.getcwd() + '\\database2'\n",
    "print(path)\n",
    "#dataset_name = 'apple2orange'\n",
    "\n",
    "#DOWNLOAD_URL = 'https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets/{}.zip'.format(dataset_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generators using the U-net architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_generator(img_shape,channels=3,num_filters=64):\n",
    "    \"\"\"U-Net Generator\"\"\"\n",
    "\n",
    "    def upsample_block(incoming_layer,skip_input_layer,num_filters,kernel_size=4,dropout_rate=0):\n",
    "        \"\"\"Layers used during upsampling\"\"\"\n",
    "        upsample_layer = UpSampling2D(size=2)(incoming_layer)\n",
    "        upsample_layer = Conv2D(num_filters,kernel_size=kernel_size,strides=1,padding='same',activation='relu')(upsample_layer)\n",
    "        if dropout_rate:\n",
    "            upsample_layer = Dropout(dropout_rate)(upsample_layer)\n",
    "            upsample_layer = BatchNormalization(momentum=0.8)(upsample_layer)\n",
    "            upsample_layer = Concatenate()([upsample_layer, skip_input_layer])\n",
    "        return upsample_layer   \n",
    "    \n",
    "    def downsample_block(incoming_layer,num_filters,kernel_size=4,batch_normalization=True):\n",
    "        \"\"\"Layers used during downsampling\"\"\"\n",
    "        downsample_layer = Conv2D(num_filters,kernel_size=kernel_size,strides=2, padding='same')(incoming_layer)\n",
    "        downsample_layer = LeakyReLU(alpha=0.2)(downsample_layer)\n",
    "        if batch_normalization:\n",
    "            downsample_layer = BatchNormalization(momentum=0.8)(downsample_layer)\n",
    "        return downsample_layer\n",
    "\n",
    "    # Image input\n",
    "    input_layer = Input(shape=img_shape)\n",
    "    # Downsampling\n",
    "    down_sample_1 = downsample_block(input_layer,\n",
    "    num_filters,\n",
    "    batch_normalization=False)\n",
    "    # rest of the downsampling blocks have batch_normalization=true\n",
    "    down_sample_2 = downsample_block(down_sample_1, num_filters*2)\n",
    "    down_sample_3 = downsample_block(down_sample_2, num_filters*4)\n",
    "    down_sample_4 = downsample_block(down_sample_3, num_filters*8)\n",
    "    down_sample_5 = downsample_block(down_sample_4, num_filters*8)\n",
    "    down_sample_6 = downsample_block(down_sample_5, num_filters*8)\n",
    "    down_sample_7 = downsample_block(down_sample_6, num_filters*8)\n",
    "    # Upsampling blocks with skip connections\n",
    "    upsample_1 = upsample_block(down_sample_7, down_sample_6,num_filters*8)\n",
    "    upsample_2 = upsample_block(upsample_1, down_sample_5,num_filters*8)\n",
    "    upsample_3 = upsample_block(upsample_2, down_sample_4,num_filters*8)\n",
    "    upsample_4 = upsample_block(upsample_3, down_sample_3,num_filters*8)\n",
    "    upsample_5 = upsample_block(upsample_4, down_sample_2,num_filters*2)\n",
    "    upsample_6 = upsample_block(upsample_5, down_sample_1, num_filters)\n",
    "    upsample_7 = UpSampling2D(size=2)(upsample_6)\n",
    "    output_img = Conv2D(channels,kernel_size=4,strides=1,padding='same',activation='tanh')(upsample_7)\n",
    "    return Model(input_layer, output_img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discriminator function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(img_shape,num_filters=64):\n",
    "    \"\"\" discrimitator block \"\"\"\n",
    "    def discriminator_block(incoming_layer,num_filters,kernel_size = 4,instance_normalization=True):\n",
    "        disc_layer = Conv2D(num_filters,kernel_size=kernel_size,strides=2,padding='same')(incoming_layer)\n",
    "        disc_layer = LeakyReLU(alpha = 0.2)(disc_layer)\n",
    "        if instance_normalization:\n",
    "            disc_layer = InstanceNormalization()(disc_layer)\n",
    "        return disc_layer\n",
    "\n",
    "    input_layer = Input(shape=img_shape)\n",
    "    #first layer not normalized\n",
    "    disc_block_1 = discriminator_block(input_layer,num_filters,instance_normalization=False)\n",
    "    disc_block_2 = discriminator_block(disc_block_1, num_filters*2)\n",
    "    disc_block_3 = discriminator_block(disc_block_2, num_filters*4)\n",
    "    disc_block_4 = discriminator_block(disc_block_3, num_filters*8)\n",
    "    output = Conv2D(1, kernel_size=4, strides=1, padding='same')(disc_block_4)\n",
    "    \n",
    "    return Model(input_layer, output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAN setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patch Shape=(32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "generator_filters = 32\n",
    "discriminator_filters = 64\n",
    "\n",
    "# input shape\n",
    "channels = 3\n",
    "input_shape = (IMG_HEIGHT, IMG_WIDTH, channels)\n",
    "# Loss weights\n",
    "lambda_cycle = 10.0\n",
    "\n",
    "lambda_identity = 0.1 * lambda_cycle\n",
    "optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "# prepare patch size for our setup\n",
    "patch = int(IMG_HEIGHT / 2**4)\n",
    "patch_gan_shape = (patch, patch, 1)\n",
    "print(\"Patch Shape={}\".format(patch_gan_shape))\n",
    "\n",
    "# Discriminators\n",
    "disc_A = build_discriminator(input_shape,discriminator_filters)\n",
    "disc_A.compile(loss='mse',optimizer=optimizer,metrics=['accuracy'])\n",
    "disc_B = build_discriminator(input_shape,discriminator_filters)\n",
    "disc_B.compile(loss='mse',optimizer=optimizer,metrics=['accuracy'])\n",
    "\n",
    "# Generators\n",
    "gen_AB = build_generator(input_shape,channels, generator_filters)\n",
    "gen_BA = build_generator(input_shape, channels, generator_filters)\n",
    "\n",
    "# CycleGAN\n",
    "img_A = Input(shape=input_shape)\n",
    "img_B = Input(shape=input_shape)\n",
    "\n",
    "# generate fake samples from both generators\n",
    "fake_B = gen_AB(img_A)\n",
    "fake_A = gen_BA(img_B)\n",
    "\n",
    "# reconstruct original samples from both generators\n",
    "reconstruct_A = gen_BA(fake_B)\n",
    "reconstruct_B = gen_AB(fake_A)\n",
    "\n",
    "# generate identity samples\n",
    "identity_A = gen_BA(img_A)\n",
    "identity_B = gen_AB(img_B)\n",
    "\n",
    "# disable discriminator training\n",
    "disc_A.trainable = False\n",
    "disc_B.trainable = False\n",
    "\n",
    "# use discriminator to classify real vs fake\n",
    "output_A = disc_A(fake_A)\n",
    "output_B = disc_B(fake_B)\n",
    "\n",
    "# Combined model trains generators to fool discriminators\n",
    "gan = Model(inputs=[img_A, img_B],\n",
    "outputs=[output_A, output_B,reconstruct_A, reconstruct_B,identity_A, identity_B ])\n",
    "\n",
    "gan.compile(loss=['mse', 'mse','mae', 'mae','mae', 'mae'],loss_weights=[1, 1,lambda_cycle, lambda_cycle,lambda_identity, lambda_identity ],optimizer=optimizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that generates a batch of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(path,\n",
    "                    batch_size=1,\n",
    "                    image_res=[128, 128],\n",
    "                    is_testing=False):\n",
    "    \"\"\"\n",
    "    Method to generate batch of images\n",
    "    Parameters:\n",
    "        path: type:str. Path to the dataset\n",
    "        batch_size: type:int. Number of images required\n",
    "        image_res: type:int list. Array denoting the resized [H,W] of image\n",
    "        is_testing: type: bool. Flag to control random flipping\n",
    "    Returns:\n",
    "        yields a tuple of two lists (source,target)\n",
    "    \"\"\"\n",
    "    data_type = \"train\" if not is_testing else \"test\"\n",
    "    path_A = glob('{}/{}A/*'.format(path, data_type))\n",
    "    path_B = glob('{}/{}B/*'.format(path, data_type))\n",
    "\n",
    "    num_batches = int(min(len(path_A), len(path_B)) / batch_size)\n",
    "    num_samples = num_batches * batch_size\n",
    "\n",
    "    # get num_samples from each domain\n",
    "    path_A = np.random.choice(path_A, num_samples, replace=False)\n",
    "    path_B = np.random.choice(path_B, num_samples, replace=False)\n",
    "\n",
    "    for i in range(num_batches-1):\n",
    "        batch_A = path_A[i*batch_size:(i+1)*batch_size]\n",
    "        batch_B = path_B[i*batch_size:(i+1)*batch_size]\n",
    "        imgs_A, imgs_B = [], []\n",
    "        for img_A, img_B in zip(batch_A, batch_B):\n",
    "            img_A = imread(img_A, image_res)\n",
    "            img_B = imread(img_B, image_res)\n",
    "\n",
    "            if not is_testing and np.random.random() > 0.5:\n",
    "                img_A = np.fliplr(img_A)\n",
    "                img_B = np.fliplr(img_B)\n",
    "\n",
    "            imgs_A.append(img_A)\n",
    "            imgs_B.append(img_B)\n",
    "\n",
    "        imgs_A = np.array(imgs_A)\n",
    "        imgs_B = np.array(imgs_B)\n",
    "\n",
    "        yield imgs_A, imgs_B\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(gen_AB,gen_BA,disc_A,disc_B,gan,patch_gan_shape,epochs,\n",
    "            path,batch_size=1,sample_interval=50):\n",
    "\n",
    "    # Adversarial loss ground truths\n",
    "    real_y = np.ones((batch_size,) + patch_gan_shape)\n",
    "    fake_y = np.zeros((batch_size,) + patch_gan_shape)\n",
    "    for epoch in range(epochs):\n",
    "        print(\"Epoch={}\".format(epoch))\n",
    "        for idx, (imgs_A, imgs_B) in enumerate(batch_generator(path,batch_size,image_res=[IMG_HEIGHT, IMG_WIDTH])):\n",
    "            print(idx)\n",
    "            # train discriminators\n",
    "            # generate fake samples from both generators\n",
    "            fake_B = gen_AB.predict(imgs_A)\n",
    "            fake_A = gen_BA.predict(imgs_B)\n",
    "            # Train the discriminators\n",
    "            # (original images = real / translated = Fake)\n",
    "            disc_A_loss_real = disc_A.train_on_batch(imgs_A, real_y)\n",
    "            disc_A_loss_fake = disc_A.train_on_batch(fake_A, fake_y)\n",
    "            disc_A_loss = 0.5 * np.add(disc_A_loss_real,disc_A_loss_fake)\n",
    "\n",
    "            disc_B_loss_real = disc_B.train_on_batch(imgs_B, real_y)\n",
    "            disc_B_loss_fake = disc_B.train_on_batch(fake_B, fake_y)\n",
    "            disc_B_loss = 0.5 * np.add(disc_B_loss_real,disc_B_loss_fake)\n",
    "            \n",
    "            # Total disciminator loss\n",
    "            discriminator_loss = 0.5 * np.add(disc_A_loss, disc_B_loss)\n",
    "\n",
    "            # train generator\n",
    "            gen_loss = gan.train_on_batch([imgs_A, imgs_B],[real_y, real_y,imgs_A, imgs_B,imgs_A, imgs_B])\n",
    "\n",
    "            # training updates every 50 iterations\n",
    "            if idx % 50 == 0:\n",
    "                print (\"[Epoch {}/{}] [Discriminator loss: {}, accuracy:{}][Generator loss: {}, Adversarial Loss: {}, Reconstruction Loss: {},Identity Loss: {}]\".format(idx,epochs,discriminator_loss[0],100*discriminator_loss[1],\n",
    "                        gen_loss[0],np.mean(gen_loss[1:3]),np.mean(gen_loss[3:5]),np.mean(gen_loss[5:6])))\n",
    "        \n",
    "            # Plot and Save progress every few iterations\n",
    "            if idx % sample_interval == 0:\n",
    "                plot_sample_images(gen_AB,gen_BA,path=path,epoch=epoch,batch_num=idx,output_dir='images')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DL dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n tf.keras.utils.get_file('{}.tar.gz'.format(dataset_name),\\n                         origin=DOWNLOAD_URL,\\n                         cache_subdir='/content',\\n                         extract=True) \""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    " tf.keras.utils.get_file('{}.tar.gz'.format(dataset_name),\n",
    "                         origin=DOWNLOAD_URL,\n",
    "                         cache_subdir='/content',\n",
    "                         extract=True) '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample_images(gen_AB,\n",
    "                       gen_BA,\n",
    "                       path,\n",
    "                       epoch=0,\n",
    "                       batch_num=1,\n",
    "                       output_dir='maps'):\n",
    "    \"\"\"\n",
    "    Method to plot sample outputs from generator\n",
    "    Parameters:\n",
    "        g_AB        :   type:keras model object. Generator model from A->B\n",
    "        gen_BA      :   type:keras model object. Generator model from B->A\n",
    "        path        :   type:str. Path to dataset\n",
    "        epoch       :   type:int. Epoch number, used for output file name\n",
    "        batch_num   :   type:int. Batch number, used for output file name\n",
    "        output_dir  :   type:str. Path to save generated output samples\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    imgs_A = get_samples(path, domain=\"A\", batch_size=1, is_testing=True)\n",
    "    imgs_B = get_samples(path, domain=\"B\", batch_size=1, is_testing=True)\n",
    "\n",
    "    # generate fake samples from both generators\n",
    "    fake_B = gen_AB.predict(imgs_A)\n",
    "    fake_A = gen_BA.predict(imgs_B)\n",
    "\n",
    "    # reconstruct orginal samples from both generators\n",
    "    reconstruct_A = gen_BA.predict(fake_B)\n",
    "    reconstruct_B = gen_AB.predict(fake_A)\n",
    "\n",
    "    gen_imgs = np.concatenate([imgs_A, fake_B,\n",
    "                               reconstruct_A,\n",
    "                               imgs_B, fake_A,\n",
    "                               reconstruct_B])\n",
    "\n",
    "    # scale images 0 - 1\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    titles = ['Original', 'Translated', 'Reconstructed']\n",
    "\n",
    "    r, c = 2, 3\n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "      for j in range(c):\n",
    "          axs[i,j].imshow(gen_imgs[cnt])\n",
    "          axs[i, j].set_title(titles[j])\n",
    "          axs[i,j].axis('off')\n",
    "          cnt += 1\n",
    "    fig.savefig(\"{}/{}_{}.png\".format(output_dir, epoch, batch_num))\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples(path,\n",
    "                domain='A',\n",
    "                batch_size=1,\n",
    "                image_res=[128, 128],\n",
    "                is_testing=False):\n",
    "    \"\"\"\n",
    "    Method to get a random sample of images\n",
    "    Parameters:\n",
    "        path        : type:str. Path to the dataset\n",
    "        domain: type:str. Domain A or B to pick samples from.\n",
    "        batch_size  : type:int. Number of images required\n",
    "        image_res   : type:int list. Array denoting the resized [H,W] of image\n",
    "        is_testing  : type: bool. Flag to control random flipping\n",
    "    Returns:\n",
    "        A list of randomly sampled images\n",
    "    \"\"\"\n",
    "    data_type = \"train%s\" % domain if not is_testing else \"test%s\" % domain\n",
    "    path = glob('{}/{}/*'.format(path, data_type))\n",
    "\n",
    "    random_sample = np.random.choice(path, size=batch_size)\n",
    "\n",
    "    imgs = []\n",
    "    for img_path in random_sample:\n",
    "        img = imread(img_path, image_res)\n",
    "        if not is_testing and np.random.random() > 0.5:\n",
    "            img = np.fliplr(img)\n",
    "        imgs.append(img)\n",
    "\n",
    "    return np.array(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imread(path, image_res=[128, 128]):\n",
    "    \"\"\"\n",
    "    Utility to read image in RGB format and normalize it\n",
    "    Parameters:\n",
    "        path        : type:list. Path to the image to be loaded\n",
    "        image_res   : type:int list. Array denoting the resized [H,W] of image\n",
    "    Returns:\n",
    "        A normalized and resized image\n",
    "    \"\"\"\n",
    "    img = plt.imread(path).astype(np.float64)\n",
    "    #img = tf.image.resize(img, image_res).numpy()\n",
    "\n",
    "    img = img/127.5 - 1.\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=0\n",
      "0\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 512, 512, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 512, 512, 3), dtype=tf.float32, name='input_15'), name='input_15', description=\"created by layer 'input_15'\"), but it was called on an input with incompatible shape (None, 512, 512).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\Utilisateur\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Utilisateur\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Utilisateur\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\Utilisateur\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\Utilisateur\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\Utilisateur\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 228, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"model_12\" (type Functional).\n    \n    Input 0 of layer \"conv2d_86\" is incompatible with the layer: expected min_ndim=4, found ndim=3. Full shape received: (None, 512, 512)\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None, 512, 512), dtype=float32)\n      • training=False\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7736\\33196422.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m train(gen_AB,gen_BA,disc_A,disc_B,gan,patch_gan_shape,500,\n\u001b[0m\u001b[0;32m      2\u001b[0m             path,batch_size=1,sample_interval=50)\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7736\\442587300.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(gen_AB, gen_BA, disc_A, disc_B, gan, patch_gan_shape, epochs, path, batch_size, sample_interval)\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[1;31m# train discriminators\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[1;31m# generate fake samples from both generators\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[0mfake_B\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_AB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs_A\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m             \u001b[0mfake_A\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_BA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs_B\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[1;31m# Train the discriminators\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Utilisateur\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Utilisateur\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1146\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1147\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1148\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\Utilisateur\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Utilisateur\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Utilisateur\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\Utilisateur\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\Utilisateur\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\Utilisateur\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 228, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"model_12\" (type Functional).\n    \n    Input 0 of layer \"conv2d_86\" is incompatible with the layer: expected min_ndim=4, found ndim=3. Full shape received: (None, 512, 512)\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None, 512, 512), dtype=float32)\n      • training=False\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "train(gen_AB,gen_BA,disc_A,disc_B,gan,patch_gan_shape,500,\n",
    "            path,batch_size=1,sample_interval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'a' cannot be empty unless no samples are taken",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16136\\2706275970.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_sample_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen_AB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen_BA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16136\\221755656.py\u001b[0m in \u001b[0;36mplot_sample_images\u001b[1;34m(gen_AB, gen_BA, path, epoch, batch_num, output_dir)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \"\"\"\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mimgs_A\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdomain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"A\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_testing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0mimgs_B\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdomain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"B\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_testing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16136\\2893781737.py\u001b[0m in \u001b[0;36mget_samples\u001b[1;34m(path, domain, batch_size, image_res, is_testing)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{}/{}/*'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mrandom_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mimgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: 'a' cannot be empty unless no samples are taken"
     ]
    }
   ],
   "source": [
    "plot_sample_images(gen_AB, gen_BA, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a3d0e8e0c817ae3c7f78f66b04bafeb63523a0a50e6405ec1b074461715681e4"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
